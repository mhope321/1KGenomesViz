paste(name)
depth <- data.frame(geno(trimmed)$DP,geno(trimmed)$RO,
geno(trimmed)$AO,row.names=names(trimmed))
samples_names <- (samples(header(trimmed)))
n_samples <- length(samples_names)
for (val1 in 1:n_samples)
{
depth <- cbind(depth,sapply(1:nrow(depth),get_percentage_ref,var2=val1))
}
for (val2 in 1:n_samples)
{
tmp2 <- (2*n_samples)+val2
lapply_test2<- lapply(depth[,tmp2],get_percentage_allele,var2=nrow(depth),var3=val2)
name <- toString((3*n_samples)+val2)
depth$paste(name) = lapply_test2
}
depth <- data.frame(geno(trimmed)$DP,geno(trimmed)$RO,
geno(trimmed)$AO,row.names=names(trimmed))
samples_names <- (samples(header(trimmed)))
n_samples <- length(samples_names)
for (val1 in 1:n_samples)
{
depth <- cbind(depth,sapply(1:nrow(depth),get_percentage_ref,var2=val1))
}
for (val2 in 1:n_samples)
{
tmp2 <- (2*n_samples)+val2
lapply_test2<- lapply(depth[,tmp2],get_percentage_allele,var2=nrow(depth),var3=val2)
name <- (3*n_samples)+val2
depth$name = lapply_test2
}
View(depth)
depth <- data.frame(geno(trimmed)$DP,geno(trimmed)$RO,
geno(trimmed)$AO,row.names=names(trimmed))
samples_names <- (samples(header(trimmed)))
n_samples <- length(samples_names)
for (val1 in 1:n_samples)
{
depth <- cbind(depth,sapply(1:nrow(depth),get_percentage_ref,var2=val1))
}
depth[9] <- lapply_test2
head(lapply_test2)
depth2 <- list(geno(trimmed)$DP,geno(trimmed)$RO,
geno(trimmed)$AO)
View(depth2)
names(depth2)
length(depth2[1])
length(depth2[[1]])
length(names(trimmed))
as.data.frame(lapply_test2)
data.frame(lapply_test2)
length(lapply_test2)
typeof(lapply_test2)
typeof(depth)
typeof(depth[1,2])
typeof(depth[1])
typeof(depth[2])
typeof(depth[3])
typeof(depth[,3])
depth <- data.frame(geno(trimmed)$DP,geno(trimmed)$RO,
geno(trimmed)$AO,row.names=names(trimmed))
samples_names <- (samples(header(trimmed)))
n_samples <- length(samples_names)
for (val1 in 1:n_samples)
{
depth <- cbind(depth,sapply(1:nrow(depth),get_percentage_ref,var2=val1))
}
lapply_test2<- lapply(depth[,tmp2],get_percentage_allele,var2=nrow(depth),var3=val2)
name
paste0("depth$",name," = lapply_test2")
colnames(depth)
grep(get,colnames(depth))
grep("get",colnames(depth))
depth[grep("get",colnames(depth))]
#VCF-Annotate
#v1.
#Matt Hope, 11-06-2019
#Input: Rscript VCF-Annotate.R name_of_vcf_file.vcf
#The purpose of this code is to annotate every variant in a VCF file with three sets of key
#information: 1) the type of variant, as assessed by the Bioconductor package VariantAnnotation
#2) the read depth for the site of the variant, number of reads supporting the allele(s),
#and percentage of reads supporting the reference vs allele(s), and 3) the allele frequency
#of the variant from the ExAC database, if the variant is available.
#Packages
#Several Bioconductor packages are required, as are the packages "httr" and "jsonlite"
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
if (!require(VariantAnnotation)) BiocManager::install("VariantAnnotation")
library(VariantAnnotation)
if (!require(GenomicRanges)) BiocManager::install("GenomicRanges")
library(GenomicRanges)
if (!require(GenomicFeatures)) BiocManager::install("GenomicFeatures")
library(GenomicFeatures)
if (!require(TxDb.Hsapiens.UCSC.hg19.knownGene)) BiocManager::install("TxDb.Hsapiens.UCSC.hg19.knownGene")
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
if (!require(GenomeInfoDb)) BiocManager::install("GenomeInfoDb")
library(GenomeInfoDb)
if (!require(BSgenome)) BiocManager::install("BSgenome")
library(BSgenome)
if (!require(BSgenome.Hsapiens.UCSC.hg19)) BiocManager::install("BSgenome.Hsapiens.UCSC.hg19")
library(BSgenome.Hsapiens.UCSC.hg19)
if (!require(httr)) install.packages("httr")
library(httr)
if (!require(jsonlite)) install.packages("jsonlite")
library(jsonlite)
#Functions
#type_of_variant
#Function to choose most deleterious variant. This function checks all the
#entries for a given QUERYID, and selects the maximal factor based on a
# set order (intergenic<intron<promoter<threeUTR<fiveUTR<coding<spliceSite).
#If the variant is coding, it is then checked within the coding order of
#impact (synonymous<nonsynonymous<framshift<nonsense).
#In some cases, locateVariants might skip over a value for a QUERYID. In
#this case, the variable temp is set to order(), which has length equal to zero,
#and is used to set the variable temp to an error level.
type_of_variant <- function(input)
{
temp <- allvar_df[allvar_df$query==input,2]
if(length(temp))
{
temp <- max(temp)
}
else
{
temp <- factor(x=c("Error in locateVariants"),
levels = levels(allvar_df[,2]),ordered = TRUE)
}
if (temp=="coding")
{
temp <- max(coding_df[coding_df$query==input,2])
}
return(temp)
}
#get_percentage_ref
#Function to take RO and DP fields for a given sample and return
#the percentage of reads supporting the reference.
get_percentage_ref <- function(var1,var2)
{
tmp <- (depth[var1,(var2+n_samples)]/depth[var1,var2])
return(tmp)
}
#get_percentage_allele
#Function to take AO and DP fields for a given sample and return
#the percentage of reads supporting the allele.
get_percentage_allele <- function(var1,var2,var3)
{
tmp <- var1/depth[var2,var3]
return(tmp)
}
#get_allele_freq
#Function to parse just allele_freq values from the ExAC dataframe.
#If the variant queried does not exist in the database, it is marked
#as such and returned.
get_allele_freq <- function(input)
{
tmp <- input$allele_freq
if(is.null(tmp))
{
tmp<-"Variant not in ExAC"
}
return(tmp)
}
#Part1
#Get VCF file input.
args <- commandArgs(trailingOnly = TRUE)
#file_name <- args[1]
file_name <- "/Users/Matt/Downloads/Tempus-Challenge/Challenge_data.vcf"
#Create a VCF object. The parameters passed through ScanVcfParam read in
#relevant data from the INFO and FORMAT fields, instead of all data.
vcf <- readVcf(file_name,"hg19",param=ScanVcfParam(info="DP",geno=c("DP","RO","AO")))
#Get TxDb file input. Here we're using Hg19 from UCSC
txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene
#Fix vcf levels to UCSC style, to match txdb
seqlevels(vcf) <- paste0("chr", seqlevels(vcf))
names <- c(paste0("chr",1:22),"chrX","chrY")
trimmed <- keepSeqlevels(vcf,names)
#Note this will drop any variants in unassigned contigs or the
#mitochrondrial genome
#Part 2
#Assess type of variant
#Locate variants. The function locateVariants relies on a GRanges object, not
#a VCF object, so we extract a GRanges object first to pass to the function.
rd <- rowRanges(trimmed)
allvar <- locateVariants(rd, txdb, AllVariants())
#Predict impact of coding variants. The function predictCoding requires a VCF
#object ("trimmed"), a txdb, and a BSGenome object in order to call changes
#to codons. Here we're using BSGenome.Hsapiens.UCSC.hg19
coding <- predictCoding(trimmed, txdb, Hsapiens)
#Subset allvar object, taking just the QUERYID and TYPE as a dataframe
allvar_df <- data.frame(mcols(allvar)$QUERYID,mcols(allvar)$LOCATION)
colnames(allvar_df) <- c("query","loc")
#Set order of impact for all variants, from least deleterious to most deleterious.
#Note that the highest level is reserved for an error state from locateVariants.
allvar_df[,2] <- factor(allvar_df[,2],c("intergenic","intron","promoter",
"threeUTR","fiveUTR","coding","spliceSite","Error in locateVariants"),ordered=TRUE)
#Subset coding variant object, taking just the QUERYID and CONSEQUENCE as a dataframe
coding_df <- data.frame(mcols(coding)$QUERYID,mcols(coding)$CONSEQUENCE)
colnames(coding_df) <- c("query","cons")
#Set order of impact for coding variants, from least deleterious to most deleterious.
coding_df[,2] <- factor(coding_df[,2],c("synonymous","nonsynonymous",
"frameshift","nonsense"),ordered=TRUE)
#Assess type of variation; type_of_variant instantiated above.
variant_types <- sapply((1:length(trimmed)),type_of_variant)
#Part 3
#Sequence depth and allele count information
#Get data from FORMAT field of VCF file
depth <- data.frame(geno(trimmed)$DP,geno(trimmed)$RO,
geno(trimmed)$AO,row.names=names(trimmed))
samples_names <- (samples(header(trimmed)))
n_samples <- length(samples_names)
#Calculate the percentage of reads suporting the reference for every sample
for (val1 in 1:n_samples)
{
depth <- cbind(depth,sapply(1:nrow(depth),get_percentage_ref,var2=val1))
}
#Calculate the percentage of reads supoorting the allele for two samples.
val2 <- 1
tmp <- (2*n_samples)+val2
depth$allele_percent1 = lapply(depth[,tmp2],get_percentage_allele,var2=nrow(depth),var3=val2)
val2 <- 2
tmp <- (2*n_samples)+val2
depth$allele_percent2 = lapply(depth[,tmp2],get_percentage_allele,var2=nrow(depth),var3=val2)
#Rename columns to label their outputs
colnames(depth) <- c(paste0("Depth: ",samples_names),paste0("Ref count: ",samples_names),
paste0("Allele count: ",samples_names), paste0("Percentage reference: ",samples_names),
paste0("Percentage allele: ",samples_names))
#Part 3
#Sequence depth and allele count information
#Get data from FORMAT field of VCF file
depth <- data.frame(geno(trimmed)$DP,geno(trimmed)$RO,
geno(trimmed)$AO,row.names=names(trimmed))
samples_names <- (samples(header(trimmed)))
n_samples <- length(samples_names)
#Calculate the percentage of reads suporting the reference for every sample
for (val1 in 1:n_samples)
{
depth <- cbind(depth,sapply(1:nrow(depth),get_percentage_ref,var2=val1))
}
#Calculate the percentage of reads supoorting the allele for two samples.
val2 <- 1
tmp <- (2*n_samples)+val2
depth$allele_percent1 = lapply(depth[,tmp],get_percentage_allele,var2=nrow(depth),var3=val2)
val2 <- 2
tmp <- (2*n_samples)+val2
depth$allele_percent2 = lapply(depth[,tmp],get_percentage_allele,var2=nrow(depth),var3=val2)
#Rename columns to label their outputs
colnames(depth) <- c(paste0("Depth: ",samples_names),paste0("Ref count: ",samples_names),
paste0("Allele count: ",samples_names), paste0("Percentage reference: ",samples_names),
paste0("Percentage allele: ",samples_names))
#Part 4
#Query ExAc Databse
#Get the names of the variants
variants_names <- names(trimmed)
#Alter the format to be readable by the ExAC database (CHROMOSOME-POSITION-REFERENCE-VARIANT), i.e. only dashes between fields
subbed <- gsub(":|_|/","-",variants_names)
#Convert to JSON array to comply with bulk query specifications
query_json <- toJSON(subbed)
#Query the ExAC databse for the variants,and convert the query back to
#a dataframe. This section relies on the packages httr and jsonlite.
#POST is used instead of GET to comply with the ExAC API bulk specifications.
exac_url <- "http://exac.hms.harvard.edu/rest/bulk/variant/variant"
getinfo <- POST(url = exac_url, body = query_json, encode = "json")
variant_text <- content(getinfo, as="text", encoding="UTF-8")
variant_json <- fromJSON(variant_text, flatten=TRUE)
#Get allele_freqs across all variants
allele_freqs <- sapply(variant_json,get_allele_freq)
#Re-order the allele_freqs names to match the original input
allele_freqs_ordered <- allele_freqs[order(factor(names(allele_freqs),
levels = subbed, ordered = TRUE))]
#Part 4
output_df <- data.frame(variant_types,depth[grep("Depth:",colnames(depth))],
depth[grep("Allele count:",colnames(depth))],
depth[grep("Percentage allele:",colnames(depth))],
depth[grep("Percentage reference:",colnames(depth))],
allele_freqs_ordered,row.names = names(trimmed))
View(output_df)
#Write filname.out
write.csv(output_df, file = paste0(filename,".out"))
#Write filname.out
write.csv(output_df, file = paste0(file_name,".out"))
write.table(output_df, file = paste0(file_name,".out"))
typeof(output_df)
typeof(output_df[1])
typeof(output_df[,1])
unlist(output_df)
test_unlist<-unlist(output_df)
head(test_unlist)
df <- apply(df,2,as.character)
df <- apply(output_df,2,as.character)
View(df)
write.table(df, file = paste0(file_name,".out"))
output_df <- data.frame(variant_types,depth[grep("Depth:",colnames(depth))],
depth[grep("Allele count:",colnames(depth))],
depth[grep("Percentage allele:",colnames(depth))],
depth[grep("Percentage reference:",colnames(depth))],
allele_freqs_ordered,row.names = names(trimmed))
output_df <- apply(output_df,2,as.character)
write.csv(output_df, row.names = TRUE file = paste0(file_name,".out"))
write.csv(output_df, row.names = TRUE, file = paste0(file_name,".out"))
View(output_df)
output_df <- data.frame(names(trimmed),variant_types,depth[grep("Depth:",colnames(depth))],
depth[grep("Allele count:",colnames(depth))],
depth[grep("Percentage allele:",colnames(depth))],
depth[grep("Percentage reference:",colnames(depth))],
allele_freqs_ordered,row.names = FALSE)
output_df <- data.frame(names(trimmed),variant_types,depth[grep("Depth:",colnames(depth))],
depth[grep("Allele count:",colnames(depth))],
depth[grep("Percentage allele:",colnames(depth))],
depth[grep("Percentage reference:",colnames(depth))],
allele_freqs_ordered)
output_df <- apply(output_df,2,as.character)
write.csv(output_df, row.names = TRUE, file = paste0(file_name,".out"))
source('~/Downloads/Tempus-Challenge/VCF-Annotate.R')
source('~/Downloads/Tempus-Challenge/VCF-Annotate.R')
#file_name <- args[1]
file_name <- "/Users/Matt/Downloads/Tempus-Challenge/Challenge_data.vcf"
source('~/Downloads/Tempus-Challenge/VCF-Annotate.R')
source('~/Downloads/Tempus-Challenge/VCF-Annotate.R')
source('~/Downloads/Tempus-Challenge/VCF-Annotate.R')
names(sessionInfo()$loadedOnly)
library()
load("~/Downloads/Wufilter_DP.Rdata")
View(result.Wu)
result.Wu.gene
result.Wu.result.gene
result.Wu
result.Wu$result.gene
load("~/Downloads/Wustress_DP2.Rdata")
View(result.Osm)
result.Osm$result.gene
result.Osm$result.gene$padj
test_df <- result.Osm$result.gene[order(padj),]
test_df <- result.Osm$result.gene[order($padj),]
test_df <- result.Osm$result.gene
test_df[,order("padj")]
test_df
test_df[order(test_df$padj),]
test_df2 <- test_df[order(test_df$padj),]
test_df2[1:200,]
test_df2[1:300,]
test_df2[1:250,]
rownames(test_df2[1:250,])
write.csv(rownames(test_df2[1:250,]))
write.csv(rownames(test_df2[1:250,]),file=OsmGenes.csv)
write.csv(rownames(test_df2[1:250,]),file="OsmGenes.csv")
ox_df <- result.Ox$result.gene
ox_df2 <- ox_df[order(ox_df$padj),]
ox_df2
head(test_df2)
head(ox_df2)
write.csv(rownames(ox_df2[1:250,]),file="OxGenes.csv")
ox_df3 <- ox_df[order(ox_df$DC,),]
ox_df
ox_df3 <- ox_df[order(ox_df$DC),]
ox_df3
write.csv(rownames(ox_df3[1:250,]),file="OxGenes-DC.csv")
ox_df4 <- ox_df[order(ox_df$padj,-ox_df$DC),]
ox_df4
ox_df2
head(ox_df2)
head(ox_df4)
ox_df5 <- ox_df[,(ox_df$DC>.1)]
ox_df5 <- subset(ox_df,subset=(ox_df$DC>0.05),select=c(ox_df$tvalue:ox_df$DC))
ox_df5 <- subset(ox_df,subset=(ox_df$DC>0.05),select=c(ox_df$tvalue,ox_df$padj,ox_df$DC))
ox_df5
View(ox_df5)
rm(ox_df5)
ox_df5 <- subset(ox_df,subset=(ox_df$DC>0.05),select=c(ox_df$tvalue:ox_df$DC))
ox_df5 <- subset(ox_df,subset=(ox_df$DC>0.05))
ox_df5
ox_df
ox_df4
ox_df3
ox_df5
ox_df4
result.Wu
View(result.Wu)
load("~/Downloads/DA_erf1d (1).Rdata")
View(newdata)
install.packages("tidyverse")
runif(10)
runif(10)
replicate(5,runif(10))
replicate(5,runif(10),simplify = FALSE)
replicate(5,runif(10),simplify = TRUE)
replicate(4,runif(10),simplify = TRUE)
xs <- replicate(5,runif(10),simplify = FALSE)
xs
lapply(xs,mean)
lapply(xs,mean())
lapply(xs,mean)
lapply(xs,mean)
unlist(lapply(xs,mean))
xs
ws <- replicate(5, rpois(10, 5) + 1, simplify = FALSE)
ws
Map(weighted.mean, xs, ws)
map(weighted.mean, xs, ws)
Reduce(sum,1:3)
Reduce(sum,1:4)
Reduce(sum,c(1,2,3,4))
Reduce('+',c(1,2,3,4))
Reduce('*',c(1,2,3,4))
Reduce('*',c(2,1,3,4))
Reduce('*',c(2,1,3,4),accumulate = TRUE)
Reduce('*',c(1,2,3,4),accumulate = TRUE)
df <- data.frame(x=1:6,
y=rep(c("Low", "High"),3),
z=I(LETTERS[1:6]),
row.names=paste("Sample", 1:6, sep="_"))
df
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
if (!require(GenomicRanges)) BiocManager::install("GenomicRanges")
library(GenomicRanges)
if (!require(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)) BiocManager::install("TxDb.Scerevisiae.UCSC.sacCer3.sgdGene")
library(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)
if (!require(BSgenome)) BiocManager::install("BSgenome")
library(BSgenome)
if (!require(BSgenome.Scerevisiae.UCSC.sacCer3)) BiocManager::install("BSgenome.Scerevisiae.UCSC.sacCer3")
library(BSgenome.Scerevisiae.UCSC.sacCer3)
library(stringr)
txdb <- TxDb.Scerevisiae.UCSC.sacCer3.sgdGene
bs <- BSgenome.Scerevisiae.UCSC.sacCer3
yeast_genes_set1 <- read.csv("/Users/Matt/Desktop/WangLab/200121-StopCodonAnalysis/Set1.csv", stringsAsFactors = FALSE,header=FALSE)
yeast_set1_df <- as.data.frame(yeast_genes_set1[,1:5])
names(yeast_set1_df) <- c("TXNAME","chromosome","start","end","strand")
set1_granges <- makeGRangesFromDataFrame(yeast_set1_df,keep.extra.columns = TRUE)
set1_result <- getSeq(bs,set1_granges,as.character=TRUE)
sum(set1_result=="TAA")
sum(set1_result=="TAG")
sum(set1_result=="TGA")
length(set1_result)
yeast_genes_set2 <- read.csv("/Users/Matt/Desktop/WangLab/200121-StopCodonAnalysis/Set2.csv", stringsAsFactors = FALSE,header=FALSE)
yeast_set2_df <- as.data.frame(yeast_genes_set2[,1:5])
names(yeast_set2_df) <- c("TXNAME","chromosome","start","end","strand")
set2_granges <- makeGRangesFromDataFrame(yeast_set2_df,keep.extra.columns = TRUE)
set2_result <- getSeq(bs,set2_granges,as.character=TRUE)
sum(set2_result=="TAA")
sum(set2_result=="TAG")
sum(set2_result=="TGA")
length(set2_result)
yeast_genes_all <- read.csv("/Users/Matt/Desktop/WangLab/200121-StopCodonAnalysis/YeastStopCodons2.csv", stringsAsFactors = FALSE,header=FALSE)
yeast_all_df <- as.data.frame(yeast_genes_all[,1:5])
names(yeast_all_df) <- c("TXNAME","chromosome","start","end","strand")
all_stop_codons_granges <- makeGRangesFromDataFrame(yeast_all_df,keep.extra.columns = TRUE)
all_stop_codons_result <- getSeq(bs,all_stop_codons_granges,as.character=TRUE)
sum(all_stop_codons_result=="TAA")
sum(all_stop_codons_result=="TAG")
sum(all_stop_codons_result=="TGA")
length(all_stop_codons_result)
source('~/Desktop/NYCDSA/10KGen/10KGen/global.R')
library(tidyr)
source('~/Desktop/NYCDSA/10KGen/10KGen/global.R')
source('~/Desktop/NYCDSA/10KGen/10KGen/global.R')
runApp()
source('~/Desktop/NYCDSA/10KGen/10KGen/global.R')
runApp()
runApp()
runApp()
runApp()
runApp()
vars[vars$name=="ETS1","id"]
runApp()
runApp()
runApp()
test = vars %>% filter(name=="ETS1")
test
test %>% gather(key="AF",value="freq",AF,AF_AFR,AF_AMR,AF_EAS,AF_EUR,AF_SAS)
g = test %>% gather(key="AF",value="freq",AF,AF_AFR,AF_AMR,AF_EAS,AF_EUR,AF_SAS) %>%
ggplot(aes(x=AF,y=freq))+geom_col()
g
h = test %>% gather(key="AF",value="freq",AF,AF_AFR,AF_AMR,AF_EAS,AF_EUR,AF_SAS) %>%
group_by(AF) %>% summarise(freq = mean(freq)) %>%
ggplot(aes(x=AF,y=freq))+geom_col()
h = test %>% gather(key="AF",value="freq",AF,AF_AFR,AF_AMR,AF_EAS,AF_EUR,AF_SAS) %>%
group_by(AF) %>% summarise(freq = mean(freq))
h = test %>% gather(key="AF",value="freq",AF,AF_AFR,AF_AMR,AF_EAS,AF_EUR,AF_SAS)
h
h %>% group_by(AF) %>% summarise(mean(freq))
h %>% group_by(AF) %>% summarise(n())
h %>% group_by(AF) %>% summarise(mean(freq))
h %>% group_by(AF) %>% summarise(sum(freq))
h %>% group_by(AF)
h %>% group_by(AF) %>% select(freq)
typeof(h %>% group_by(AF) %>% select(freq))
(h %>% group_by(AF) %>% select(freq)[1]
q
(h %>% group_by(AF) %>% select(freq) %>% [1]
h %>% group_by(AF) %>% summarise(n())
h %>% group_by(AF) %>% summarise(sum(freq))
h %>% group_by(AF) %>% summarise(sum(as.numeric(freq)))
h %>% group_by(AF) %>% summarise(mean(as.numeric(freq)))
i = h %>% group_by(AF) %>% summarise(ave = mean(as.numeric(freq)))
i %>% ggplot(aes(x=AF,y=ave))+geom_col()
i %>% ggplot(aes(x=AF,y=ave))+geom_col(color=AF)
i %>% ggplot(aes(x=AF,y=ave))+geom_col(aes(fill=AF))
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
test
test %>% gather(key="AF",value="freq",AF,AF_AFR,AF_AMR,AF_EAS,AF_EUR,AF_SAS) %>%
ggplot(aes(x=AF,y=freq,fill=AF))+geom_boxplot()
test %>% gather(key="AF",value="freq",AF,AF_AFR,AF_AMR,AF_EAS,AF_EUR,AF_SAS) %>%
ggplot(aes(x=AF,y=freq,fill=AF))+geom_boxplot()
test %>% gather(key="AF",value="freq",AF,AF_AFR,AF_AMR,AF_EAS,AF_EUR,AF_SAS) %>% mutate(freq=as.numeric(freq)) %>% ggplot(aes(x=AF,y=freq,fill=AF))+geom_boxplot()
test
test %>% arrange(desc(AF_AFR))
test %>% arrange(desc(AF))
